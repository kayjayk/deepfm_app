{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " # <font color='red'>GPU Seeting</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensorflow version :  2.3.1\n",
      "keras version :  2.4.0\n",
      "WARNING:tensorflow:From <ipython-input-1-a141e1751472>:18: is_gpu_available (from tensorflow.python.framework.test_util) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.config.list_physical_devices('GPU')` instead.\n",
      "GPU available ? :  True\n"
     ]
    }
   ],
   "source": [
    "# gpu number setting\n",
    "import os\n",
    "os.environ['CUDA_DEVICE_ORDER'] = 'PCI_BUS_ID'\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = '1'\n",
    "\n",
    "# Gpu growth setting\n",
    "import tensorflow as tf\n",
    "config = tf.compat.v1.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "session = tf.compat.v1.Session(config=config)\n",
    "\n",
    "\n",
    "# tensorflow & keras version check\n",
    "print('tensorflow version : ' , tf.__version__)\n",
    "print('keras version : ' , tf.keras.__version__)\n",
    "\n",
    "# tensorflow gpu available check \n",
    "print('GPU available ? : ', tf.test.is_gpu_available(cuda_only=False, min_cuda_compute_capability=None))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " # <font color='red'>Import</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import tqdm\n",
    "import math\n",
    "import itertools\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "pd.options.display.max_columns = 50\n",
    "\n",
    "from sklearn.metrics import log_loss, roc_auc_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, MinMaxScaler, MultiLabelBinarizer\n",
    "\n",
    "from deepctr.models import DeepFM\n",
    "from deepctr.layers import custom_objects\n",
    "from deepctr.feature_column import SparseFeat,DenseFeat, get_feature_names, VarLenSparseFeat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 경로설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_path = './'\n",
    "\n",
    "# model_weight_dir = os.path.join(root_path, 'model_weight')\n",
    "rec_list_dir = os.path.join(root_path, 'rec_list')\n",
    "\n",
    "# model weight save path\n",
    "# if not os.path.exists(model_weight_dir) :\n",
    "#     os.makedirs(model_weight_dir)\n",
    "\n",
    "# rec_list_dir save path\n",
    "if not os.path.exists(rec_list_dir) :\n",
    "    os.makedirs(rec_list_dir)   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " # <font color='red'>데이터</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow2_p36/lib/python3.6/site-packages/IPython/core/interactiveshell.py:3063: DtypeWarning: Columns (0) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv('../../../../../../../ipr/data/tb_ipr_m_seamless_2nd_iptv.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data[data['meta'] == 'movie']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* training 과 동일하게 조작"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "drops = ['sum_watch_duration', 's_time', 'e_time', 'album_name', 'gubun', \n",
    "         'vod_s_point', 'vod_e_point', 'agree_yn', 'min_s_time', \n",
    "         'view_no', 'fod', 'buy_1_2', 'buy_3', 'buy_seg', 'amt_r_gubun',\n",
    "         'weekdays', 'weekends', 'dawn', 'morning', 'afternoon', 'evening',\n",
    "         'watch_ratio', 'current_rate', 're_watch', 'continue_watch',\n",
    "#          'buy_history_price',\n",
    "        'meta_genre', 'genre_large', 'genre_mid', 'genre_small',\n",
    "         'pr_info_desc', 'meta'\n",
    "        ]\n",
    "\n",
    "data.drop(columns=drops, inplace=True)\n",
    "\n",
    "# data['sum_watch_duration'] = data['sum_watch_duration'].fillna(0)\n",
    "\n",
    "data['category_id'] = data['category_id'].fillna('n')\n",
    "\n",
    "price_cols = ['movie_meta_price', 'buy_history_price', 'i30_meta_price']\n",
    "data[price_cols] = data[price_cols].fillna(0)\n",
    "\n",
    "data = data[data['amt_1_4'].isnull() == False]\n",
    "\n",
    "data['sa_id'] = data['sa_id'].apply(lambda x: str(x))\n",
    "data['album_id'] = data['album_id'].apply(lambda x: str(x))\n",
    "\n",
    "data['watcha_avg_rating'] = data['watcha_avg_rating'].fillna(data['watcha_avg_rating'].mean())\n",
    "data['ncf_rating'] = data['ncf_rating'].fillna(data['ncf_rating'].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "sparse_features = ['sa_id', 'album_id', 'category_id', 'pr_info'\n",
    "#                    'buy_seg'\n",
    "                  ]\n",
    "dense_features = ['release_date', 'run_time', \n",
    "                  'movie_meta_price', 'i30_meta_price', 'buy_history_price', 'buy_tot',\n",
    "                  'amt_1_4', 'amt_2_4', 'amt_3_4', 'amt_4_4', 'watcha_avg_rating']\n",
    "target = ['ncf_rating']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color='red'>label encoding </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./lbe_dict.pickle', 'rb') as f:\n",
    "    lbe_dict = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "for feat in sparse_features:\n",
    "    data[feat] = lbe_dict[feat].transform(data[feat])\n",
    "\n",
    "mms = MinMaxScaler(feature_range=(0, 1))\n",
    "data[dense_features] = mms.fit_transform(data[dense_features])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_pred_dir = './rec_list/'\n",
    "\n",
    "with open(os.path.join(model_pred_dir,'unique_uid.csv'),'a') as out_file:\n",
    "    np.savetxt(out_file, np.vstack((lbe_dict['sa_id'].classes_,list(range(len(lbe_dict['sa_id'].classes_))))).T, delimiter=',', fmt=['%s','%i'])        \n",
    "\n",
    "with open(os.path.join(model_pred_dir,'unique_sid.csv'),'a') as out_file:\n",
    "    np.savetxt(out_file, np.vstack((lbe_dict['album_id'].classes_,list(range(len(lbe_dict['album_id'].classes_))))).T, delimiter=',', fmt=['%s','%i'])    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# sa_id & album_id meta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "sa_feats = ['buy_tot', 'amt_1_4', 'amt_2_4', 'amt_3_4', 'amt_4_4']\n",
    "album_feats = ['category_id', 'release_date', 'run_time',\n",
    "              'movie_meta_price', 'i30_meta_price', 'buy_history_price',\n",
    "              'watcha_avg_rating', 'pr_info'\n",
    "              ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "sa_id_meta = data.groupby('sa_id')[sa_feats].max()\n",
    "album_id_meta = data.groupby('album_id')[album_feats].max()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# model load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4.Define Model,train,predict and evaluate\n",
    "model = tf.keras.models.load_model('./model/', custom_objects)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "nsa_id = data['sa_id'].nunique()\n",
    "nalbum_id = data['album_id'].nunique()\n",
    "album_array = np.sort(data['album_id'].unique())\n",
    "topk = 300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_user(num_users, batch_size=1):\n",
    "    user_list = np.sort(data['sa_id'].unique())\n",
    "    for idx in np.arange(0, num_users, batch_size):\n",
    "        yield user_list[idx : min(idx + batch_size, num_users)]        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3830/3830 [52:52<00:00,  1.21it/s]\n"
     ]
    }
   ],
   "source": [
    "temp_batch_album = np.tile(album_array, 300)\n",
    "\n",
    "album_id_meta_dict = dict()\n",
    "for temp_col in album_id_meta.columns :\n",
    "    album_id_meta_dict[temp_col] = album_id_meta.loc[temp_batch_album, temp_col].values\n",
    "\n",
    "with open('./rec_list/rec.csv','a') as out_file:\n",
    "    with tqdm.tqdm(total=math.ceil(nsa_id/300)) as pbar:\n",
    "        for batch_u in batch_user(nsa_id, 300):\n",
    "            temp_batch_sa = np.repeat(batch_u, nalbum_id)\n",
    "            \n",
    "            # batch 마지막 처리\n",
    "            if len(batch_u) != 300 :\n",
    "                temp_batch_album = np.tile(album_array, len(batch_u))\n",
    "                album_id_meta_dict = dict()\n",
    "                for temp_col in album_id_meta.columns :\n",
    "                    album_id_meta_dict[temp_col] = album_id_meta.loc[temp_batch_album, temp_col].values\n",
    "            \n",
    "            temp_batch_input = {'sa_id' : temp_batch_sa, 'album_id' : temp_batch_album}\n",
    "            \n",
    "            # album_meta 추가\n",
    "            temp_batch_input.update(album_id_meta_dict)\n",
    "            \n",
    "            # sa_id_meta 추가\n",
    "            for temp_col in sa_id_meta.columns :\n",
    "                temp_batch_input[temp_col] = sa_id_meta.loc[temp_batch_sa, temp_col].values\n",
    "           \n",
    "            #pred = model.predict_on_batch(temp_batch_input)\n",
    "            pred = model(temp_batch_input).numpy()\n",
    "            pred_mat = pred.reshape(-1,nalbum_id)\n",
    "            \n",
    "            user_idx = 0\n",
    "            \n",
    "            for temp_pred in pred_mat:\n",
    "                temp_topk = np.argsort(temp_pred)[::-1][:topk]\n",
    "                temp_score = temp_pred[temp_topk]   \n",
    "                temp_df = np.column_stack((np.full(topk, batch_u[user_idx]),temp_topk, temp_score))\n",
    "                \n",
    "                \n",
    "                fmt = ','.join(['%i','%i','%1.5f'])\n",
    "                fmt = '\\n'.join([fmt]*temp_df.shape[0])\n",
    "                data = fmt % tuple(temp_df.ravel())      \n",
    "                out_file.write(data)\n",
    "                user_idx += 1\n",
    "            \n",
    "            pbar.update(1)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tensorflow2_p36]",
   "language": "python",
   "name": "conda-env-tensorflow2_p36-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
