{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensorflow version :  2.3.1\n",
      "keras version :  2.4.0\n",
      "WARNING:tensorflow:From <ipython-input-1-a95b7deb4494>:18: is_gpu_available (from tensorflow.python.framework.test_util) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.config.list_physical_devices('GPU')` instead.\n",
      "GPU available ? :  True\n"
     ]
    }
   ],
   "source": [
    "# gpu number setting\n",
    "import os\n",
    "os.environ['CUDA_DEVICE_ORDER'] = 'PCI_BUS_ID'\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = '1' ## gpu 번호 셋팅 윤건 :0, 기준 : 1, 준형 :2,\n",
    "\n",
    "# Gpu growth setting\n",
    "import tensorflow as tf\n",
    "config = tf.compat.v1.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "session = tf.compat.v1.Session(config=config)\n",
    "\n",
    "\n",
    "# tensorflow & keras version check\n",
    "print('tensorflow version : ' , tf.__version__)\n",
    "print('keras version : ' , tf.keras.__version__)\n",
    "\n",
    "# tensorflow gpu available check \n",
    "print('GPU available ? : ', tf.test.is_gpu_available(cuda_only=False, min_cuda_compute_capability=None))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import tqdm\n",
    "import random\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', 100)\n",
    "pd.set_option('display.max_rows', 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../../Data/movie_201118_table_5.pickle', 'rb') as f:\n",
    "    raw = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* final drop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_genre = 33"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "sparse_features = ['sa_id', 'album_id', 'buy_seg'] + [str(i) for i in range(num_genre)]\n",
    "dense_features = ['release_date', 'run_time', 'movie_meta_price', 'i30_meta_price', 'buy_tot',\n",
    "                  'amt_1_4', 'amt_2_4', 'amt_3_4', 'amt_4_4']\n",
    "unnecessary_features = ['index', 'meta_genre', 'genre_large', 'genre_mid', 'genre_small', 'buy_history_price']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "51\n",
      "36\n",
      "9\n",
      "6\n"
     ]
    }
   ],
   "source": [
    "print(len(raw.columns))\n",
    "print(len(sparse_features))\n",
    "print(len(dense_features))\n",
    "print(len(unnecessary_features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw.drop(columns=unnecessary_features, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "raw['label'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow2_p36/lib/python3.6/site-packages/ipykernel_launcher.py:2: UserWarning: DataFrame columns are not unique, some columns will be omitted.\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "958.6114776134491\n"
     ]
    }
   ],
   "source": [
    "tmp = time.time()\n",
    "data_dict = raw.set_index(keys=['sa_id', 'album_id']).T.to_dict('list')\n",
    "print(time.time() - tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_col = ['sa_id', 'buy_seg', 'buy_tot']\n",
    "cont_col = ['album_id', 'release_date', 'run_time', 'movie_meta_price', 'i30_meta_price',\n",
    "                'amt_1_4', 'amt_2_4', 'amt_3_4', 'amt_4_4'] + [str(i) for i in range(num_genre)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* all data -> user_table & content_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_tab = raw[user_col]\n",
    "cont_tab = raw[cont_col]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* duplicate rows 제거"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_uni_tab = user_tab.loc[list(user_tab['sa_id'].drop_duplicates().index)]\n",
    "cont_uni_tab = cont_tab.loc[list(cont_tab['album_id'].drop_duplicates().index)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "album_id_list = list(cont_uni_tab['album_id'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* original method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_train_instances(train, num_negatives, album_id_list):\n",
    "    '''\n",
    "    설명 : train matrix를 받아서 그 안에 있는 user, item의 조합 1개당 num_negatives의 수만큼 negative sample을 만드는 함수.\n",
    "    '''\n",
    "    user_input, item_input, labels = [],[],[]\n",
    "    \n",
    "    train_keys = train.keys()\n",
    "#     train_items = train.items()\n",
    "    for (u, i) in tqdm.tqdm(train_keys):       \n",
    "        # positive instance\n",
    "        user_input.append(u)\n",
    "        item_input.append(i)\n",
    "        labels.append(1)\n",
    "        \n",
    "        # negative instances\n",
    "        for _ in range(num_negatives):\n",
    "            j = random.randint(0, len(album_id_list) - 1)\n",
    "            album = album_id_list[j]\n",
    "            while (u, album) in train_keys :\n",
    "                j = random.randint(0, len(album_id_list) - 1)\n",
    "                album = album_id_list[j]\n",
    "            user_input.append(u)\n",
    "            item_input.append(album)\n",
    "            labels.append(0)\n",
    "#             output_dict[(u, j)] = 0\n",
    "            \n",
    "        \n",
    "    return user_input, item_input, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7786135/7786135 [00:40<00:00, 194424.26it/s]\n"
     ]
    }
   ],
   "source": [
    "user_input, item_input, labels = get_train_instances(data_dict, 2, album_id_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df = pd.DataFrame({'sa_id': user_input, 'album_id':item_input, 'label':labels})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "merge_df = pd.merge(final_df, user_uni_tab, how='inner', on='sa_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "merge_df_2 = pd.merge(merge_df, cont_uni_tab, how='inner', on='album_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../../Data/movie_201118_table_6_2.pickle', 'wb') as f:\n",
    "    pickle.dump(merge_df_2, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tensorflow2_p36]",
   "language": "python",
   "name": "conda-env-tensorflow2_p36-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
