{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensorflow version :  2.3.1\n",
      "keras version :  2.4.0\n",
      "WARNING:tensorflow:From <ipython-input-1-a95b7deb4494>:18: is_gpu_available (from tensorflow.python.framework.test_util) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.config.list_physical_devices('GPU')` instead.\n",
      "GPU available ? :  True\n"
     ]
    }
   ],
   "source": [
    "# gpu number setting\n",
    "import os\n",
    "os.environ['CUDA_DEVICE_ORDER'] = 'PCI_BUS_ID'\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = '1' ## gpu 번호 셋팅 윤건 :0, 기준 : 1, 준형 :2,\n",
    "\n",
    "# Gpu growth setting\n",
    "import tensorflow as tf\n",
    "config = tf.compat.v1.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "session = tf.compat.v1.Session(config=config)\n",
    "\n",
    "\n",
    "# tensorflow & keras version check\n",
    "print('tensorflow version : ' , tf.__version__)\n",
    "print('keras version : ' , tf.keras.__version__)\n",
    "\n",
    "# tensorflow gpu available check \n",
    "print('GPU available ? : ', tf.test.is_gpu_available(cuda_only=False, min_cuda_compute_capability=None))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import tqdm\n",
    "import random\n",
    "import time\n",
    "\n",
    "from sklearn.metrics import log_loss, roc_auc_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, MinMaxScaler\n",
    "\n",
    "from deepctr.models import *\n",
    "from deepctr.feature_column import SparseFeat, DenseFeat, get_feature_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', 100)\n",
    "pd.set_option('display.max_rows', 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "with open('../Data/raw_mod_4_negative_sample.pickle', 'rb') as f:\n",
    "    data = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "sparse_features = ['sa_id', 'album_id', 'buy_seg']\n",
    "dense_features = ['release_date', 'run_time', 'movie_meta_price', 'i30_meta_price', 'buy_history_price','buy_tot',\n",
    "                  'amt_1_4', 'amt_2_4', 'amt_3_4', 'amt_4_4']\n",
    "# ambiguous_features = [ 'agree_yn', 'meta_genre', 'genre_large', 'genre_mid', 'genre_small']\n",
    "# unnecessary_features = ['category_id', # NaN 약 650만 중에 25만 정도.\n",
    "#                         's_time', 'e_time', # future\n",
    "#                         'watch_duration', # future\n",
    "#                          # \\\\N 값이 약 482만 개\n",
    "#                         'vod_s_point', 'vod_e_point', \n",
    "#                         'album_name',\n",
    "#                         'view_no',\n",
    "#                         'fod', 'buy_1_2', 'buy_3',\n",
    "#                         'amt_r_gabun',\n",
    "#                         'watch_ratio',\n",
    "#                         'weekdays', 'weekends', 'dawn', 'morning', 'afternoon', 'evening',\n",
    "#                         'current_rate']\n",
    "target = ['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "fixlen_feature_columns = [SparseFeat(feat, vocabulary_size=data[feat].nunique(),embedding_dim=4)\n",
    "                           for i,feat in enumerate(sparse_features)]\n",
    "\n",
    "dnn_feature_columns = fixlen_feature_columns\n",
    "linear_feature_columns = fixlen_feature_columns\n",
    "\n",
    "feature_names = get_feature_names(linear_feature_columns + dnn_feature_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = train_test_split(data, test_size=0.2, random_state=2020)\n",
    "train_model_input = {name:train[name] for name in feature_names}\n",
    "test_model_input = {name:test[name] for name in feature_names}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1849491"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "924878"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(test['label'] == 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = DeepFM(linear_feature_columns, dnn_feature_columns, task='binary')\n",
    "model.compile(\"adam\", \"binary_crossentropy\", metrics=['binary_crossentropy'], )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow2_latest_p37/lib/python3.7/site-packages/tensorflow/python/framework/indexed_slices.py:433: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/23 - 1s - loss: 0.6830 - binary_crossentropy: 0.6829 - val_loss: 0.6605 - val_binary_crossentropy: 0.6603\n",
      "Epoch 2/200\n",
      "23/23 - 1s - loss: 0.6006 - binary_crossentropy: 0.6001 - val_loss: 0.5023 - val_binary_crossentropy: 0.5014\n",
      "Epoch 3/200\n",
      "23/23 - 1s - loss: 0.4082 - binary_crossentropy: 0.4067 - val_loss: 0.3400 - val_binary_crossentropy: 0.3379\n",
      "Epoch 4/200\n",
      "23/23 - 1s - loss: 0.3241 - binary_crossentropy: 0.3215 - val_loss: 0.3181 - val_binary_crossentropy: 0.3150\n",
      "Epoch 5/200\n",
      "23/23 - 1s - loss: 0.3062 - binary_crossentropy: 0.3023 - val_loss: 0.3176 - val_binary_crossentropy: 0.3128\n",
      "Epoch 6/200\n",
      "23/23 - 1s - loss: 0.2900 - binary_crossentropy: 0.2843 - val_loss: 0.3303 - val_binary_crossentropy: 0.3236\n",
      "Epoch 7/200\n",
      "23/23 - 1s - loss: 0.2761 - binary_crossentropy: 0.2685 - val_loss: 0.3418 - val_binary_crossentropy: 0.3335\n",
      "Epoch 8/200\n",
      "23/23 - 1s - loss: 0.2662 - binary_crossentropy: 0.2574 - val_loss: 0.3483 - val_binary_crossentropy: 0.3392\n",
      "Epoch 9/200\n",
      "23/23 - 1s - loss: 0.2587 - binary_crossentropy: 0.2493 - val_loss: 0.3497 - val_binary_crossentropy: 0.3401\n",
      "Epoch 10/200\n",
      "23/23 - 1s - loss: 0.2512 - binary_crossentropy: 0.2415 - val_loss: 0.3504 - val_binary_crossentropy: 0.3405\n",
      "Epoch 11/200\n",
      "23/23 - 1s - loss: 0.2420 - binary_crossentropy: 0.2320 - val_loss: 0.3537 - val_binary_crossentropy: 0.3434\n",
      "Epoch 12/200\n",
      "23/23 - 1s - loss: 0.2306 - binary_crossentropy: 0.2200 - val_loss: 0.3622 - val_binary_crossentropy: 0.3513\n",
      "Epoch 13/200\n",
      "23/23 - 1s - loss: 0.2196 - binary_crossentropy: 0.2084 - val_loss: 0.3724 - val_binary_crossentropy: 0.3609\n",
      "Epoch 14/200\n",
      "23/23 - 1s - loss: 0.2112 - binary_crossentropy: 0.1996 - val_loss: 0.3805 - val_binary_crossentropy: 0.3688\n",
      "Epoch 15/200\n",
      "23/23 - 1s - loss: 0.2052 - binary_crossentropy: 0.1935 - val_loss: 0.3858 - val_binary_crossentropy: 0.3741\n",
      "Epoch 16/200\n",
      "23/23 - 1s - loss: 0.2004 - binary_crossentropy: 0.1888 - val_loss: 0.3896 - val_binary_crossentropy: 0.3780\n",
      "Epoch 17/200\n",
      "23/23 - 1s - loss: 0.1966 - binary_crossentropy: 0.1850 - val_loss: 0.3934 - val_binary_crossentropy: 0.3819\n",
      "Epoch 18/200\n",
      "23/23 - 1s - loss: 0.1932 - binary_crossentropy: 0.1817 - val_loss: 0.3969 - val_binary_crossentropy: 0.3854\n",
      "Epoch 19/200\n",
      "23/23 - 1s - loss: 0.1901 - binary_crossentropy: 0.1787 - val_loss: 0.3998 - val_binary_crossentropy: 0.3884\n",
      "Epoch 20/200\n",
      "23/23 - 1s - loss: 0.1872 - binary_crossentropy: 0.1758 - val_loss: 0.4029 - val_binary_crossentropy: 0.3915\n",
      "Epoch 21/200\n",
      "23/23 - 1s - loss: 0.1842 - binary_crossentropy: 0.1728 - val_loss: 0.4065 - val_binary_crossentropy: 0.3952\n",
      "Epoch 22/200\n",
      "23/23 - 1s - loss: 0.1810 - binary_crossentropy: 0.1697 - val_loss: 0.4088 - val_binary_crossentropy: 0.3975\n",
      "Epoch 23/200\n",
      "23/23 - 1s - loss: 0.1779 - binary_crossentropy: 0.1666 - val_loss: 0.4136 - val_binary_crossentropy: 0.4023\n",
      "Epoch 24/200\n",
      "23/23 - 1s - loss: 0.1746 - binary_crossentropy: 0.1633 - val_loss: 0.4189 - val_binary_crossentropy: 0.4076\n",
      "Epoch 25/200\n",
      "23/23 - 1s - loss: 0.1714 - binary_crossentropy: 0.1601 - val_loss: 0.4220 - val_binary_crossentropy: 0.4107\n",
      "Epoch 26/200\n",
      "23/23 - 1s - loss: 0.1684 - binary_crossentropy: 0.1571 - val_loss: 0.4265 - val_binary_crossentropy: 0.4151\n",
      "Epoch 27/200\n",
      "23/23 - 1s - loss: 0.1655 - binary_crossentropy: 0.1541 - val_loss: 0.4314 - val_binary_crossentropy: 0.4200\n",
      "Epoch 28/200\n",
      "23/23 - 1s - loss: 0.1627 - binary_crossentropy: 0.1512 - val_loss: 0.4354 - val_binary_crossentropy: 0.4239\n",
      "Epoch 29/200\n",
      "23/23 - 1s - loss: 0.1600 - binary_crossentropy: 0.1486 - val_loss: 0.4386 - val_binary_crossentropy: 0.4271\n",
      "Epoch 30/200\n",
      "23/23 - 1s - loss: 0.1577 - binary_crossentropy: 0.1461 - val_loss: 0.4401 - val_binary_crossentropy: 0.4285\n",
      "Epoch 31/200\n",
      "23/23 - 1s - loss: 0.1555 - binary_crossentropy: 0.1439 - val_loss: 0.4474 - val_binary_crossentropy: 0.4358\n",
      "Epoch 32/200\n",
      "23/23 - 1s - loss: 0.1534 - binary_crossentropy: 0.1417 - val_loss: 0.4503 - val_binary_crossentropy: 0.4387\n",
      "Epoch 33/200\n",
      "23/23 - 1s - loss: 0.1516 - binary_crossentropy: 0.1400 - val_loss: 0.4530 - val_binary_crossentropy: 0.4413\n",
      "Epoch 34/200\n",
      "23/23 - 1s - loss: 0.1500 - binary_crossentropy: 0.1383 - val_loss: 0.4561 - val_binary_crossentropy: 0.4443\n",
      "Epoch 35/200\n",
      "23/23 - 1s - loss: 0.1485 - binary_crossentropy: 0.1367 - val_loss: 0.4589 - val_binary_crossentropy: 0.4471\n",
      "Epoch 36/200\n",
      "23/23 - 1s - loss: 0.1471 - binary_crossentropy: 0.1353 - val_loss: 0.4617 - val_binary_crossentropy: 0.4499\n",
      "Epoch 37/200\n",
      "23/23 - 1s - loss: 0.1458 - binary_crossentropy: 0.1339 - val_loss: 0.4656 - val_binary_crossentropy: 0.4537\n",
      "Epoch 38/200\n",
      "23/23 - 1s - loss: 0.1445 - binary_crossentropy: 0.1326 - val_loss: 0.4671 - val_binary_crossentropy: 0.4552\n",
      "Epoch 39/200\n",
      "23/23 - 1s - loss: 0.1432 - binary_crossentropy: 0.1313 - val_loss: 0.4707 - val_binary_crossentropy: 0.4588\n",
      "Epoch 40/200\n",
      "23/23 - 1s - loss: 0.1420 - binary_crossentropy: 0.1300 - val_loss: 0.4715 - val_binary_crossentropy: 0.4595\n",
      "Epoch 41/200\n",
      "23/23 - 1s - loss: 0.1406 - binary_crossentropy: 0.1286 - val_loss: 0.4745 - val_binary_crossentropy: 0.4625\n",
      "Epoch 42/200\n",
      "23/23 - 1s - loss: 0.1392 - binary_crossentropy: 0.1272 - val_loss: 0.4772 - val_binary_crossentropy: 0.4652\n",
      "Epoch 43/200\n",
      "23/23 - 1s - loss: 0.1377 - binary_crossentropy: 0.1256 - val_loss: 0.4785 - val_binary_crossentropy: 0.4664\n",
      "Epoch 44/200\n",
      "23/23 - 1s - loss: 0.1361 - binary_crossentropy: 0.1240 - val_loss: 0.4794 - val_binary_crossentropy: 0.4673\n",
      "Epoch 45/200\n",
      "23/23 - 1s - loss: 0.1342 - binary_crossentropy: 0.1221 - val_loss: 0.4819 - val_binary_crossentropy: 0.4698\n",
      "Epoch 46/200\n",
      "23/23 - 1s - loss: 0.1321 - binary_crossentropy: 0.1199 - val_loss: 0.4829 - val_binary_crossentropy: 0.4708\n",
      "Epoch 47/200\n",
      "23/23 - 1s - loss: 0.1298 - binary_crossentropy: 0.1176 - val_loss: 0.4832 - val_binary_crossentropy: 0.4710\n",
      "Epoch 48/200\n",
      "23/23 - 1s - loss: 0.1272 - binary_crossentropy: 0.1150 - val_loss: 0.4879 - val_binary_crossentropy: 0.4757\n",
      "Epoch 49/200\n",
      "23/23 - 1s - loss: 0.1246 - binary_crossentropy: 0.1124 - val_loss: 0.4886 - val_binary_crossentropy: 0.4764\n",
      "Epoch 50/200\n",
      "23/23 - 1s - loss: 0.1221 - binary_crossentropy: 0.1100 - val_loss: 0.4914 - val_binary_crossentropy: 0.4792\n",
      "Epoch 51/200\n",
      "23/23 - 1s - loss: 0.1198 - binary_crossentropy: 0.1076 - val_loss: 0.4956 - val_binary_crossentropy: 0.4835\n",
      "Epoch 52/200\n",
      "23/23 - 1s - loss: 0.1177 - binary_crossentropy: 0.1056 - val_loss: 0.4962 - val_binary_crossentropy: 0.4840\n",
      "Epoch 53/200\n",
      "23/23 - 1s - loss: 0.1158 - binary_crossentropy: 0.1037 - val_loss: 0.4994 - val_binary_crossentropy: 0.4873\n",
      "Epoch 54/200\n",
      "23/23 - 1s - loss: 0.1141 - binary_crossentropy: 0.1020 - val_loss: 0.5032 - val_binary_crossentropy: 0.4911\n",
      "Epoch 55/200\n",
      "23/23 - 1s - loss: 0.1127 - binary_crossentropy: 0.1006 - val_loss: 0.5035 - val_binary_crossentropy: 0.4915\n",
      "Epoch 56/200\n",
      "23/23 - 1s - loss: 0.1113 - binary_crossentropy: 0.0993 - val_loss: 0.5087 - val_binary_crossentropy: 0.4966\n",
      "Epoch 57/200\n",
      "23/23 - 1s - loss: 0.1100 - binary_crossentropy: 0.0980 - val_loss: 0.5103 - val_binary_crossentropy: 0.4983\n",
      "Epoch 58/200\n",
      "23/23 - 1s - loss: 0.1089 - binary_crossentropy: 0.0969 - val_loss: 0.5129 - val_binary_crossentropy: 0.5009\n",
      "Epoch 59/200\n",
      "23/23 - 1s - loss: 0.1079 - binary_crossentropy: 0.0959 - val_loss: 0.5146 - val_binary_crossentropy: 0.5026\n",
      "Epoch 60/200\n",
      "23/23 - 1s - loss: 0.1069 - binary_crossentropy: 0.0950 - val_loss: 0.5184 - val_binary_crossentropy: 0.5064\n",
      "Epoch 61/200\n",
      "23/23 - 1s - loss: 0.1060 - binary_crossentropy: 0.0941 - val_loss: 0.5207 - val_binary_crossentropy: 0.5088\n",
      "Epoch 62/200\n",
      "23/23 - 1s - loss: 0.1051 - binary_crossentropy: 0.0932 - val_loss: 0.5206 - val_binary_crossentropy: 0.5087\n",
      "Epoch 63/200\n",
      "23/23 - 1s - loss: 0.1044 - binary_crossentropy: 0.0925 - val_loss: 0.5260 - val_binary_crossentropy: 0.5141\n",
      "Epoch 64/200\n",
      "23/23 - 1s - loss: 0.1036 - binary_crossentropy: 0.0918 - val_loss: 0.5284 - val_binary_crossentropy: 0.5165\n",
      "Epoch 65/200\n",
      "23/23 - 1s - loss: 0.1031 - binary_crossentropy: 0.0912 - val_loss: 0.5312 - val_binary_crossentropy: 0.5194\n",
      "Epoch 66/200\n",
      "23/23 - 1s - loss: 0.1024 - binary_crossentropy: 0.0905 - val_loss: 0.5300 - val_binary_crossentropy: 0.5182\n",
      "Epoch 67/200\n",
      "23/23 - 1s - loss: 0.1017 - binary_crossentropy: 0.0899 - val_loss: 0.5304 - val_binary_crossentropy: 0.5186\n",
      "Epoch 68/200\n",
      "23/23 - 1s - loss: 0.1010 - binary_crossentropy: 0.0892 - val_loss: 0.5323 - val_binary_crossentropy: 0.5205\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 69/200\n",
      "23/23 - 1s - loss: 0.1004 - binary_crossentropy: 0.0886 - val_loss: 0.5341 - val_binary_crossentropy: 0.5224\n",
      "Epoch 70/200\n",
      "23/23 - 1s - loss: 0.0999 - binary_crossentropy: 0.0881 - val_loss: 0.5369 - val_binary_crossentropy: 0.5251\n",
      "Epoch 71/200\n",
      "23/23 - 1s - loss: 0.0993 - binary_crossentropy: 0.0876 - val_loss: 0.5375 - val_binary_crossentropy: 0.5258\n",
      "Epoch 72/200\n",
      "23/23 - 1s - loss: 0.0988 - binary_crossentropy: 0.0871 - val_loss: 0.5389 - val_binary_crossentropy: 0.5272\n",
      "Epoch 73/200\n",
      "23/23 - 1s - loss: 0.0983 - binary_crossentropy: 0.0866 - val_loss: 0.5410 - val_binary_crossentropy: 0.5293\n",
      "Epoch 74/200\n",
      "23/23 - 1s - loss: 0.0978 - binary_crossentropy: 0.0861 - val_loss: 0.5438 - val_binary_crossentropy: 0.5322\n",
      "Epoch 75/200\n",
      "23/23 - 1s - loss: 0.0974 - binary_crossentropy: 0.0857 - val_loss: 0.5459 - val_binary_crossentropy: 0.5342\n",
      "Epoch 76/200\n",
      "23/23 - 1s - loss: 0.0969 - binary_crossentropy: 0.0852 - val_loss: 0.5447 - val_binary_crossentropy: 0.5330\n",
      "Epoch 77/200\n",
      "23/23 - 1s - loss: 0.0964 - binary_crossentropy: 0.0848 - val_loss: 0.5470 - val_binary_crossentropy: 0.5354\n",
      "Epoch 78/200\n",
      "23/23 - 1s - loss: 0.0960 - binary_crossentropy: 0.0844 - val_loss: 0.5473 - val_binary_crossentropy: 0.5357\n",
      "Epoch 79/200\n",
      "23/23 - 1s - loss: 0.0957 - binary_crossentropy: 0.0841 - val_loss: 0.5456 - val_binary_crossentropy: 0.5340\n",
      "Epoch 80/200\n",
      "23/23 - 1s - loss: 0.0954 - binary_crossentropy: 0.0838 - val_loss: 0.5510 - val_binary_crossentropy: 0.5394\n",
      "Epoch 81/200\n",
      "23/23 - 1s - loss: 0.0948 - binary_crossentropy: 0.0832 - val_loss: 0.5501 - val_binary_crossentropy: 0.5385\n",
      "Epoch 82/200\n",
      "23/23 - 1s - loss: 0.0944 - binary_crossentropy: 0.0828 - val_loss: 0.5506 - val_binary_crossentropy: 0.5390\n",
      "Epoch 83/200\n",
      "23/23 - 1s - loss: 0.0940 - binary_crossentropy: 0.0825 - val_loss: 0.5513 - val_binary_crossentropy: 0.5398\n",
      "Epoch 84/200\n",
      "23/23 - 1s - loss: 0.0937 - binary_crossentropy: 0.0821 - val_loss: 0.5555 - val_binary_crossentropy: 0.5440\n",
      "Epoch 85/200\n",
      "23/23 - 1s - loss: 0.0933 - binary_crossentropy: 0.0818 - val_loss: 0.5538 - val_binary_crossentropy: 0.5422\n",
      "Epoch 86/200\n",
      "23/23 - 1s - loss: 0.0931 - binary_crossentropy: 0.0815 - val_loss: 0.5575 - val_binary_crossentropy: 0.5459\n",
      "Epoch 87/200\n",
      "23/23 - 1s - loss: 0.0927 - binary_crossentropy: 0.0811 - val_loss: 0.5556 - val_binary_crossentropy: 0.5440\n",
      "Epoch 88/200\n",
      "23/23 - 1s - loss: 0.0924 - binary_crossentropy: 0.0808 - val_loss: 0.5586 - val_binary_crossentropy: 0.5470\n",
      "Epoch 89/200\n",
      "23/23 - 1s - loss: 0.0920 - binary_crossentropy: 0.0805 - val_loss: 0.5573 - val_binary_crossentropy: 0.5458\n",
      "Epoch 90/200\n",
      "23/23 - 1s - loss: 0.0917 - binary_crossentropy: 0.0801 - val_loss: 0.5587 - val_binary_crossentropy: 0.5472\n",
      "Epoch 91/200\n",
      "23/23 - 1s - loss: 0.0914 - binary_crossentropy: 0.0798 - val_loss: 0.5628 - val_binary_crossentropy: 0.5513\n",
      "Epoch 92/200\n",
      "23/23 - 1s - loss: 0.0911 - binary_crossentropy: 0.0796 - val_loss: 0.5621 - val_binary_crossentropy: 0.5505\n",
      "Epoch 93/200\n",
      "23/23 - 1s - loss: 0.0908 - binary_crossentropy: 0.0793 - val_loss: 0.5638 - val_binary_crossentropy: 0.5523\n",
      "Epoch 94/200\n",
      "23/23 - 1s - loss: 0.0906 - binary_crossentropy: 0.0791 - val_loss: 0.5644 - val_binary_crossentropy: 0.5529\n",
      "Epoch 95/200\n",
      "23/23 - 1s - loss: 0.0903 - binary_crossentropy: 0.0788 - val_loss: 0.5655 - val_binary_crossentropy: 0.5540\n",
      "Epoch 96/200\n",
      "23/23 - 1s - loss: 0.0900 - binary_crossentropy: 0.0785 - val_loss: 0.5663 - val_binary_crossentropy: 0.5548\n",
      "Epoch 97/200\n",
      "23/23 - 1s - loss: 0.0897 - binary_crossentropy: 0.0782 - val_loss: 0.5669 - val_binary_crossentropy: 0.5554\n",
      "Epoch 98/200\n",
      "23/23 - 1s - loss: 0.0894 - binary_crossentropy: 0.0779 - val_loss: 0.5677 - val_binary_crossentropy: 0.5562\n",
      "Epoch 99/200\n",
      "23/23 - 1s - loss: 0.0893 - binary_crossentropy: 0.0778 - val_loss: 0.5692 - val_binary_crossentropy: 0.5577\n",
      "Epoch 100/200\n",
      "23/23 - 1s - loss: 0.0890 - binary_crossentropy: 0.0775 - val_loss: 0.5685 - val_binary_crossentropy: 0.5571\n",
      "Epoch 101/200\n",
      "23/23 - 1s - loss: 0.0888 - binary_crossentropy: 0.0773 - val_loss: 0.5703 - val_binary_crossentropy: 0.5588\n",
      "Epoch 102/200\n",
      "23/23 - 1s - loss: 0.0885 - binary_crossentropy: 0.0771 - val_loss: 0.5736 - val_binary_crossentropy: 0.5621\n",
      "Epoch 103/200\n",
      "23/23 - 1s - loss: 0.0884 - binary_crossentropy: 0.0769 - val_loss: 0.5709 - val_binary_crossentropy: 0.5594\n",
      "Epoch 104/200\n",
      "23/23 - 1s - loss: 0.0881 - binary_crossentropy: 0.0767 - val_loss: 0.5721 - val_binary_crossentropy: 0.5606\n",
      "Epoch 105/200\n",
      "23/23 - 1s - loss: 0.0879 - binary_crossentropy: 0.0764 - val_loss: 0.5720 - val_binary_crossentropy: 0.5605\n",
      "Epoch 106/200\n",
      "23/23 - 1s - loss: 0.0876 - binary_crossentropy: 0.0761 - val_loss: 0.5738 - val_binary_crossentropy: 0.5623\n",
      "Epoch 107/200\n",
      "23/23 - 1s - loss: 0.0874 - binary_crossentropy: 0.0760 - val_loss: 0.5741 - val_binary_crossentropy: 0.5626\n",
      "Epoch 108/200\n",
      "23/23 - 1s - loss: 0.0872 - binary_crossentropy: 0.0758 - val_loss: 0.5769 - val_binary_crossentropy: 0.5654\n",
      "Epoch 109/200\n",
      "23/23 - 1s - loss: 0.0870 - binary_crossentropy: 0.0755 - val_loss: 0.5768 - val_binary_crossentropy: 0.5653\n",
      "Epoch 110/200\n",
      "23/23 - 1s - loss: 0.0869 - binary_crossentropy: 0.0754 - val_loss: 0.5773 - val_binary_crossentropy: 0.5658\n",
      "Epoch 111/200\n",
      "23/23 - 1s - loss: 0.0866 - binary_crossentropy: 0.0752 - val_loss: 0.5773 - val_binary_crossentropy: 0.5658\n",
      "Epoch 112/200\n",
      "23/23 - 1s - loss: 0.0864 - binary_crossentropy: 0.0750 - val_loss: 0.5768 - val_binary_crossentropy: 0.5653\n",
      "Epoch 113/200\n",
      "23/23 - 1s - loss: 0.0862 - binary_crossentropy: 0.0748 - val_loss: 0.5796 - val_binary_crossentropy: 0.5681\n",
      "Epoch 114/200\n",
      "23/23 - 1s - loss: 0.0861 - binary_crossentropy: 0.0746 - val_loss: 0.5817 - val_binary_crossentropy: 0.5702\n",
      "Epoch 115/200\n",
      "23/23 - 1s - loss: 0.0859 - binary_crossentropy: 0.0744 - val_loss: 0.5813 - val_binary_crossentropy: 0.5699\n",
      "Epoch 116/200\n",
      "23/23 - 1s - loss: 0.0857 - binary_crossentropy: 0.0743 - val_loss: 0.5844 - val_binary_crossentropy: 0.5729\n",
      "Epoch 117/200\n",
      "23/23 - 1s - loss: 0.0855 - binary_crossentropy: 0.0740 - val_loss: 0.5823 - val_binary_crossentropy: 0.5709\n",
      "Epoch 118/200\n",
      "23/23 - 1s - loss: 0.0853 - binary_crossentropy: 0.0739 - val_loss: 0.5830 - val_binary_crossentropy: 0.5715\n",
      "Epoch 119/200\n",
      "23/23 - 1s - loss: 0.0852 - binary_crossentropy: 0.0737 - val_loss: 0.5838 - val_binary_crossentropy: 0.5723\n",
      "Epoch 120/200\n",
      "23/23 - 1s - loss: 0.0850 - binary_crossentropy: 0.0736 - val_loss: 0.5837 - val_binary_crossentropy: 0.5722\n",
      "Epoch 121/200\n",
      "23/23 - 1s - loss: 0.0849 - binary_crossentropy: 0.0735 - val_loss: 0.5838 - val_binary_crossentropy: 0.5724\n",
      "Epoch 122/200\n",
      "23/23 - 1s - loss: 0.0847 - binary_crossentropy: 0.0732 - val_loss: 0.5870 - val_binary_crossentropy: 0.5756\n",
      "Epoch 123/200\n",
      "23/23 - 1s - loss: 0.0845 - binary_crossentropy: 0.0730 - val_loss: 0.5858 - val_binary_crossentropy: 0.5743\n",
      "Epoch 124/200\n",
      "23/23 - 1s - loss: 0.0844 - binary_crossentropy: 0.0729 - val_loss: 0.5882 - val_binary_crossentropy: 0.5768\n",
      "Epoch 125/200\n",
      "23/23 - 1s - loss: 0.0842 - binary_crossentropy: 0.0728 - val_loss: 0.5903 - val_binary_crossentropy: 0.5789\n",
      "Epoch 126/200\n",
      "23/23 - 1s - loss: 0.0841 - binary_crossentropy: 0.0726 - val_loss: 0.5863 - val_binary_crossentropy: 0.5748\n",
      "Epoch 127/200\n",
      "23/23 - 1s - loss: 0.0840 - binary_crossentropy: 0.0725 - val_loss: 0.5919 - val_binary_crossentropy: 0.5804\n",
      "Epoch 128/200\n",
      "23/23 - 1s - loss: 0.0839 - binary_crossentropy: 0.0724 - val_loss: 0.5911 - val_binary_crossentropy: 0.5796\n",
      "Epoch 129/200\n",
      "23/23 - 1s - loss: 0.0838 - binary_crossentropy: 0.0723 - val_loss: 0.5892 - val_binary_crossentropy: 0.5778\n",
      "Epoch 130/200\n",
      "23/23 - 1s - loss: 0.0836 - binary_crossentropy: 0.0722 - val_loss: 0.5933 - val_binary_crossentropy: 0.5818\n",
      "Epoch 131/200\n",
      "23/23 - 1s - loss: 0.0835 - binary_crossentropy: 0.0720 - val_loss: 0.5932 - val_binary_crossentropy: 0.5817\n",
      "Epoch 132/200\n",
      "23/23 - 1s - loss: 0.0833 - binary_crossentropy: 0.0718 - val_loss: 0.5929 - val_binary_crossentropy: 0.5814\n",
      "Epoch 133/200\n",
      "23/23 - 1s - loss: 0.0832 - binary_crossentropy: 0.0717 - val_loss: 0.5928 - val_binary_crossentropy: 0.5813\n",
      "Epoch 134/200\n",
      "23/23 - 1s - loss: 0.0830 - binary_crossentropy: 0.0715 - val_loss: 0.5970 - val_binary_crossentropy: 0.5855\n",
      "Epoch 135/200\n",
      "23/23 - 1s - loss: 0.0828 - binary_crossentropy: 0.0713 - val_loss: 0.5951 - val_binary_crossentropy: 0.5836\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 136/200\n",
      "23/23 - 1s - loss: 0.0828 - binary_crossentropy: 0.0713 - val_loss: 0.5974 - val_binary_crossentropy: 0.5859\n",
      "Epoch 137/200\n",
      "23/23 - 1s - loss: 0.0827 - binary_crossentropy: 0.0712 - val_loss: 0.5999 - val_binary_crossentropy: 0.5884\n",
      "Epoch 138/200\n",
      "23/23 - 1s - loss: 0.0824 - binary_crossentropy: 0.0709 - val_loss: 0.5995 - val_binary_crossentropy: 0.5880\n",
      "Epoch 139/200\n",
      "23/23 - 1s - loss: 0.0823 - binary_crossentropy: 0.0708 - val_loss: 0.5972 - val_binary_crossentropy: 0.5856\n",
      "Epoch 140/200\n",
      "23/23 - 1s - loss: 0.0823 - binary_crossentropy: 0.0708 - val_loss: 0.5992 - val_binary_crossentropy: 0.5877\n",
      "Epoch 141/200\n",
      "23/23 - 1s - loss: 0.0824 - binary_crossentropy: 0.0709 - val_loss: 0.6016 - val_binary_crossentropy: 0.5900\n",
      "Epoch 142/200\n",
      "23/23 - 1s - loss: 0.0823 - binary_crossentropy: 0.0708 - val_loss: 0.6023 - val_binary_crossentropy: 0.5908\n",
      "Epoch 143/200\n",
      "23/23 - 1s - loss: 0.0822 - binary_crossentropy: 0.0706 - val_loss: 0.6015 - val_binary_crossentropy: 0.5900\n",
      "Epoch 144/200\n",
      "23/23 - 1s - loss: 0.0820 - binary_crossentropy: 0.0705 - val_loss: 0.6008 - val_binary_crossentropy: 0.5893\n",
      "Epoch 145/200\n",
      "23/23 - 1s - loss: 0.0819 - binary_crossentropy: 0.0703 - val_loss: 0.6042 - val_binary_crossentropy: 0.5926\n",
      "Epoch 146/200\n",
      "23/23 - 1s - loss: 0.0817 - binary_crossentropy: 0.0701 - val_loss: 0.6006 - val_binary_crossentropy: 0.5890\n",
      "Epoch 147/200\n",
      "23/23 - 1s - loss: 0.0815 - binary_crossentropy: 0.0699 - val_loss: 0.6055 - val_binary_crossentropy: 0.5940\n",
      "Epoch 148/200\n",
      "23/23 - 1s - loss: 0.0813 - binary_crossentropy: 0.0698 - val_loss: 0.6034 - val_binary_crossentropy: 0.5918\n",
      "Epoch 149/200\n",
      "23/23 - 1s - loss: 0.0813 - binary_crossentropy: 0.0697 - val_loss: 0.6057 - val_binary_crossentropy: 0.5942\n",
      "Epoch 150/200\n",
      "23/23 - 1s - loss: 0.0812 - binary_crossentropy: 0.0697 - val_loss: 0.6053 - val_binary_crossentropy: 0.5938\n",
      "Epoch 151/200\n",
      "23/23 - 1s - loss: 0.0812 - binary_crossentropy: 0.0696 - val_loss: 0.6053 - val_binary_crossentropy: 0.5937\n",
      "Epoch 152/200\n",
      "23/23 - 1s - loss: 0.0811 - binary_crossentropy: 0.0695 - val_loss: 0.6067 - val_binary_crossentropy: 0.5952\n",
      "Epoch 153/200\n",
      "23/23 - 1s - loss: 0.0809 - binary_crossentropy: 0.0694 - val_loss: 0.6065 - val_binary_crossentropy: 0.5949\n",
      "Epoch 154/200\n",
      "23/23 - 1s - loss: 0.0809 - binary_crossentropy: 0.0693 - val_loss: 0.6077 - val_binary_crossentropy: 0.5961\n",
      "Epoch 155/200\n",
      "23/23 - 1s - loss: 0.0807 - binary_crossentropy: 0.0691 - val_loss: 0.6092 - val_binary_crossentropy: 0.5976\n",
      "Epoch 156/200\n",
      "23/23 - 1s - loss: 0.0807 - binary_crossentropy: 0.0692 - val_loss: 0.6104 - val_binary_crossentropy: 0.5989\n",
      "Epoch 157/200\n",
      "23/23 - 1s - loss: 0.0807 - binary_crossentropy: 0.0691 - val_loss: 0.6096 - val_binary_crossentropy: 0.5980\n",
      "Epoch 158/200\n",
      "23/23 - 1s - loss: 0.0806 - binary_crossentropy: 0.0690 - val_loss: 0.6111 - val_binary_crossentropy: 0.5995\n",
      "Epoch 159/200\n",
      "23/23 - 1s - loss: 0.0805 - binary_crossentropy: 0.0689 - val_loss: 0.6117 - val_binary_crossentropy: 0.6001\n",
      "Epoch 160/200\n",
      "23/23 - 1s - loss: 0.0803 - binary_crossentropy: 0.0687 - val_loss: 0.6102 - val_binary_crossentropy: 0.5985\n",
      "Epoch 161/200\n",
      "23/23 - 1s - loss: 0.0802 - binary_crossentropy: 0.0686 - val_loss: 0.6119 - val_binary_crossentropy: 0.6003\n",
      "Epoch 162/200\n",
      "23/23 - 1s - loss: 0.0801 - binary_crossentropy: 0.0685 - val_loss: 0.6156 - val_binary_crossentropy: 0.6040\n",
      "Epoch 163/200\n",
      "23/23 - 1s - loss: 0.0801 - binary_crossentropy: 0.0685 - val_loss: 0.6135 - val_binary_crossentropy: 0.6019\n",
      "Epoch 164/200\n",
      "23/23 - 1s - loss: 0.0801 - binary_crossentropy: 0.0684 - val_loss: 0.6170 - val_binary_crossentropy: 0.6054\n",
      "Epoch 165/200\n",
      "23/23 - 1s - loss: 0.0800 - binary_crossentropy: 0.0683 - val_loss: 0.6176 - val_binary_crossentropy: 0.6060\n",
      "Epoch 166/200\n",
      "23/23 - 1s - loss: 0.0799 - binary_crossentropy: 0.0683 - val_loss: 0.6153 - val_binary_crossentropy: 0.6036\n",
      "Epoch 167/200\n",
      "23/23 - 1s - loss: 0.0798 - binary_crossentropy: 0.0682 - val_loss: 0.6168 - val_binary_crossentropy: 0.6051\n",
      "Epoch 168/200\n",
      "23/23 - 1s - loss: 0.0797 - binary_crossentropy: 0.0681 - val_loss: 0.6172 - val_binary_crossentropy: 0.6056\n",
      "Epoch 169/200\n",
      "23/23 - 1s - loss: 0.0796 - binary_crossentropy: 0.0679 - val_loss: 0.6142 - val_binary_crossentropy: 0.6025\n",
      "Epoch 170/200\n",
      "23/23 - 1s - loss: 0.0795 - binary_crossentropy: 0.0679 - val_loss: 0.6195 - val_binary_crossentropy: 0.6079\n",
      "Epoch 171/200\n",
      "23/23 - 1s - loss: 0.0796 - binary_crossentropy: 0.0679 - val_loss: 0.6208 - val_binary_crossentropy: 0.6091\n",
      "Epoch 172/200\n",
      "23/23 - 1s - loss: 0.0796 - binary_crossentropy: 0.0679 - val_loss: 0.6195 - val_binary_crossentropy: 0.6078\n",
      "Epoch 173/200\n",
      "23/23 - 1s - loss: 0.0795 - binary_crossentropy: 0.0678 - val_loss: 0.6184 - val_binary_crossentropy: 0.6067\n",
      "Epoch 174/200\n",
      "23/23 - 1s - loss: 0.0794 - binary_crossentropy: 0.0677 - val_loss: 0.6186 - val_binary_crossentropy: 0.6068\n",
      "Epoch 175/200\n",
      "23/23 - 1s - loss: 0.0793 - binary_crossentropy: 0.0676 - val_loss: 0.6191 - val_binary_crossentropy: 0.6074\n",
      "Epoch 176/200\n",
      "23/23 - 1s - loss: 0.0792 - binary_crossentropy: 0.0675 - val_loss: 0.6223 - val_binary_crossentropy: 0.6105\n",
      "Epoch 177/200\n",
      "23/23 - 1s - loss: 0.0791 - binary_crossentropy: 0.0674 - val_loss: 0.6212 - val_binary_crossentropy: 0.6094\n",
      "Epoch 178/200\n",
      "23/23 - 1s - loss: 0.0791 - binary_crossentropy: 0.0673 - val_loss: 0.6217 - val_binary_crossentropy: 0.6100\n",
      "Epoch 179/200\n",
      "23/23 - 1s - loss: 0.0790 - binary_crossentropy: 0.0672 - val_loss: 0.6223 - val_binary_crossentropy: 0.6105\n",
      "Epoch 180/200\n",
      "23/23 - 1s - loss: 0.0790 - binary_crossentropy: 0.0672 - val_loss: 0.6239 - val_binary_crossentropy: 0.6122\n",
      "Epoch 181/200\n",
      "23/23 - 1s - loss: 0.0788 - binary_crossentropy: 0.0671 - val_loss: 0.6251 - val_binary_crossentropy: 0.6133\n",
      "Epoch 182/200\n",
      "23/23 - 1s - loss: 0.0789 - binary_crossentropy: 0.0671 - val_loss: 0.6273 - val_binary_crossentropy: 0.6155\n",
      "Epoch 183/200\n",
      "23/23 - 1s - loss: 0.0786 - binary_crossentropy: 0.0668 - val_loss: 0.6264 - val_binary_crossentropy: 0.6146\n",
      "Epoch 184/200\n",
      "23/23 - 1s - loss: 0.0786 - binary_crossentropy: 0.0668 - val_loss: 0.6265 - val_binary_crossentropy: 0.6147\n",
      "Epoch 185/200\n",
      "23/23 - 1s - loss: 0.0785 - binary_crossentropy: 0.0667 - val_loss: 0.6279 - val_binary_crossentropy: 0.6161\n",
      "Epoch 186/200\n",
      "23/23 - 1s - loss: 0.0785 - binary_crossentropy: 0.0667 - val_loss: 0.6281 - val_binary_crossentropy: 0.6163\n",
      "Epoch 187/200\n",
      "23/23 - 1s - loss: 0.0785 - binary_crossentropy: 0.0667 - val_loss: 0.6294 - val_binary_crossentropy: 0.6176\n",
      "Epoch 188/200\n",
      "23/23 - 1s - loss: 0.0787 - binary_crossentropy: 0.0668 - val_loss: 0.6297 - val_binary_crossentropy: 0.6179\n",
      "Epoch 189/200\n",
      "23/23 - 1s - loss: 0.0787 - binary_crossentropy: 0.0669 - val_loss: 0.6305 - val_binary_crossentropy: 0.6186\n",
      "Epoch 190/200\n",
      "23/23 - 1s - loss: 0.0786 - binary_crossentropy: 0.0667 - val_loss: 0.6299 - val_binary_crossentropy: 0.6180\n",
      "Epoch 191/200\n",
      "23/23 - 1s - loss: 0.0784 - binary_crossentropy: 0.0665 - val_loss: 0.6320 - val_binary_crossentropy: 0.6201\n",
      "Epoch 192/200\n",
      "23/23 - 1s - loss: 0.0783 - binary_crossentropy: 0.0664 - val_loss: 0.6325 - val_binary_crossentropy: 0.6206\n",
      "Epoch 193/200\n",
      "23/23 - 1s - loss: 0.0782 - binary_crossentropy: 0.0663 - val_loss: 0.6311 - val_binary_crossentropy: 0.6193\n",
      "Epoch 194/200\n",
      "23/23 - 1s - loss: 0.0782 - binary_crossentropy: 0.0663 - val_loss: 0.6332 - val_binary_crossentropy: 0.6213\n",
      "Epoch 195/200\n",
      "23/23 - 1s - loss: 0.0781 - binary_crossentropy: 0.0662 - val_loss: 0.6316 - val_binary_crossentropy: 0.6197\n",
      "Epoch 196/200\n",
      "23/23 - 1s - loss: 0.0779 - binary_crossentropy: 0.0660 - val_loss: 0.6346 - val_binary_crossentropy: 0.6227\n",
      "Epoch 197/200\n",
      "23/23 - 1s - loss: 0.0779 - binary_crossentropy: 0.0660 - val_loss: 0.6348 - val_binary_crossentropy: 0.6229\n",
      "Epoch 198/200\n",
      "23/23 - 1s - loss: 0.0778 - binary_crossentropy: 0.0659 - val_loss: 0.6355 - val_binary_crossentropy: 0.6236\n",
      "Epoch 199/200\n",
      "23/23 - 1s - loss: 0.0777 - binary_crossentropy: 0.0658 - val_loss: 0.6355 - val_binary_crossentropy: 0.6236\n",
      "Epoch 200/200\n",
      "23/23 - 1s - loss: 0.0777 - binary_crossentropy: 0.0658 - val_loss: 0.6354 - val_binary_crossentropy: 0.6235\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(train_model_input, train[target].values,\n",
    "                    batch_size=2**18, epochs=200, verbose=2, validation_split=0.2, )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow2_latest_p37/lib/python3.7/site-packages/sklearn/metrics/_classification.py:2240: RuntimeWarning: divide by zero encountered in log\n",
      "  loss = -(transformed_labels * np.log(y_pred)).sum(axis=1)\n",
      "/home/ubuntu/anaconda3/envs/tensorflow2_latest_p37/lib/python3.7/site-packages/sklearn/metrics/_classification.py:2240: RuntimeWarning: invalid value encountered in multiply\n",
      "  loss = -(transformed_labels * np.log(y_pred)).sum(axis=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test LogLoss nan\n",
      "test AUC 0.9259\n"
     ]
    }
   ],
   "source": [
    "pred_ans = model.predict(test_model_input, batch_size=32)\n",
    "print(\"test LogLoss\", round(log_loss(test[target].values, pred_ans), 4))\n",
    "print(\"test AUC\", round(roc_auc_score(test[target].values, pred_ans), 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow2_latest_p37/lib/python3.7/site-packages/tensorflow/python/framework/indexed_slices.py:433: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/23 - 2s - loss: 0.6796 - binary_crossentropy: 0.6796 - val_loss: 0.6502 - val_binary_crossentropy: 0.6500\n",
      "Epoch 2/10\n",
      "23/23 - 1s - loss: 0.5800 - binary_crossentropy: 0.5795 - val_loss: 0.4747 - val_binary_crossentropy: 0.4736\n",
      "Epoch 3/10\n",
      "23/23 - 1s - loss: 0.3884 - binary_crossentropy: 0.3869 - val_loss: 0.3337 - val_binary_crossentropy: 0.3316\n",
      "Epoch 4/10\n",
      "23/23 - 1s - loss: 0.3209 - binary_crossentropy: 0.3183 - val_loss: 0.3173 - val_binary_crossentropy: 0.3143\n",
      "Epoch 5/10\n",
      "23/23 - 1s - loss: 0.3036 - binary_crossentropy: 0.2999 - val_loss: 0.3177 - val_binary_crossentropy: 0.3132\n",
      "Epoch 6/10\n",
      "23/23 - 1s - loss: 0.2875 - binary_crossentropy: 0.2821 - val_loss: 0.3306 - val_binary_crossentropy: 0.3241\n",
      "Epoch 7/10\n",
      "23/23 - 1s - loss: 0.2742 - binary_crossentropy: 0.2670 - val_loss: 0.3400 - val_binary_crossentropy: 0.3322\n",
      "Epoch 8/10\n",
      "23/23 - 1s - loss: 0.2644 - binary_crossentropy: 0.2562 - val_loss: 0.3456 - val_binary_crossentropy: 0.3370\n",
      "Epoch 9/10\n",
      "23/23 - 1s - loss: 0.2559 - binary_crossentropy: 0.2470 - val_loss: 0.3483 - val_binary_crossentropy: 0.3391\n",
      "Epoch 10/10\n",
      "23/23 - 1s - loss: 0.2459 - binary_crossentropy: 0.2363 - val_loss: 0.3504 - val_binary_crossentropy: 0.3404\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(train_model_input, train[target].values,\n",
    "                    batch_size=2**18, epochs=10, verbose=2, validation_split=0.2, )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test LogLoss 0.3402\n",
      "test AUC 0.9311\n"
     ]
    }
   ],
   "source": [
    "pred_ans = model.predict(test_model_input, batch_size=32)\n",
    "print(\"test LogLoss\", round(log_loss(test[target].values, pred_ans), 4))\n",
    "print(\"test AUC\", round(roc_auc_score(test[target].values, pred_ans), 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1849491"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(pred_ans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([656083.,  81531.,  52135.,  44065.,  43997.,  48254.,  59745.,\n",
       "         88568., 180144., 594969.]),\n",
       " array([1.1372804e-04, 9.9692576e-02, 1.9927143e-01, 2.9885027e-01,\n",
       "        3.9842913e-01, 4.9800798e-01, 5.9758681e-01, 6.9716567e-01,\n",
       "        7.9674453e-01, 8.9632338e-01, 9.9590224e-01], dtype=float32),\n",
       " <a list of 10 Patch objects>)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(pred_ans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sa_id</th>\n",
       "      <th>album_id</th>\n",
       "      <th>label</th>\n",
       "      <th>buy_seg</th>\n",
       "      <th>buy_tot</th>\n",
       "      <th>release_date</th>\n",
       "      <th>run_time</th>\n",
       "      <th>movie_meta_price</th>\n",
       "      <th>i30_meta_price</th>\n",
       "      <th>buy_history_price</th>\n",
       "      <th>amt_1_4</th>\n",
       "      <th>amt_2_4</th>\n",
       "      <th>amt_3_4</th>\n",
       "      <th>amt_4_4</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "      <th>20</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "      <th>25</th>\n",
       "      <th>26</th>\n",
       "      <th>27</th>\n",
       "      <th>28</th>\n",
       "      <th>29</th>\n",
       "      <th>30</th>\n",
       "      <th>31</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1481322</th>\n",
       "      <td>470858</td>\n",
       "      <td>835</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.917210</td>\n",
       "      <td>0.413793</td>\n",
       "      <td>0.028571</td>\n",
       "      <td>0.028571</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5214926</th>\n",
       "      <td>714795</td>\n",
       "      <td>9438</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.835639</td>\n",
       "      <td>0.289125</td>\n",
       "      <td>0.028571</td>\n",
       "      <td>0.028571</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8291594</th>\n",
       "      <td>469153</td>\n",
       "      <td>407</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.905805</td>\n",
       "      <td>0.323607</td>\n",
       "      <td>0.028571</td>\n",
       "      <td>0.028571</td>\n",
       "      <td>0.028571</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2348943</th>\n",
       "      <td>26134</td>\n",
       "      <td>10052</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.015015</td>\n",
       "      <td>0.999745</td>\n",
       "      <td>0.286472</td>\n",
       "      <td>0.051020</td>\n",
       "      <td>0.051020</td>\n",
       "      <td>0.102041</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4609643</th>\n",
       "      <td>810607</td>\n",
       "      <td>10347</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.003003</td>\n",
       "      <td>0.999966</td>\n",
       "      <td>0.281167</td>\n",
       "      <td>0.071429</td>\n",
       "      <td>0.071429</td>\n",
       "      <td>0.102041</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4737115</th>\n",
       "      <td>283763</td>\n",
       "      <td>2473</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.612036</td>\n",
       "      <td>0.307692</td>\n",
       "      <td>0.028571</td>\n",
       "      <td>0.028571</td>\n",
       "      <td>0.028571</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8302275</th>\n",
       "      <td>682836</td>\n",
       "      <td>3936</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.006006</td>\n",
       "      <td>0.952595</td>\n",
       "      <td>0.278515</td>\n",
       "      <td>0.028571</td>\n",
       "      <td>0.028571</td>\n",
       "      <td>0.028571</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1948278</th>\n",
       "      <td>516748</td>\n",
       "      <td>651</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.799442</td>\n",
       "      <td>0.342175</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.051020</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1765768</th>\n",
       "      <td>377072</td>\n",
       "      <td>5116</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.964134</td>\n",
       "      <td>0.294430</td>\n",
       "      <td>0.028571</td>\n",
       "      <td>0.028571</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8168288</th>\n",
       "      <td>701185</td>\n",
       "      <td>9427</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.999259</td>\n",
       "      <td>0.267905</td>\n",
       "      <td>0.051020</td>\n",
       "      <td>0.051020</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7397961 rows × 46 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          sa_id  album_id  label  buy_seg   buy_tot  release_date  run_time  \\\n",
       "1481322  470858       835      1        2  0.000000      0.917210  0.413793   \n",
       "5214926  714795      9438      0        2  0.000000      0.835639  0.289125   \n",
       "8291594  469153       407      0        2  0.000000      0.905805  0.323607   \n",
       "2348943   26134     10052      1        1  0.015015      0.999745  0.286472   \n",
       "4609643  810607     10347      0        0  0.003003      0.999966  0.281167   \n",
       "...         ...       ...    ...      ...       ...           ...       ...   \n",
       "4737115  283763      2473      1        2  0.000000      0.612036  0.307692   \n",
       "8302275  682836      3936      1        0  0.006006      0.952595  0.278515   \n",
       "1948278  516748       651      1        2  0.000000      0.799442  0.342175   \n",
       "1765768  377072      5116      1        2  0.000000      0.964134  0.294430   \n",
       "8168288  701185      9427      0        2  0.000000      0.999259  0.267905   \n",
       "\n",
       "         movie_meta_price  i30_meta_price  buy_history_price  amt_1_4  \\\n",
       "1481322          0.028571        0.028571           0.000000      1.0   \n",
       "5214926          0.028571        0.028571           0.000000      1.0   \n",
       "8291594          0.028571        0.028571           0.028571      0.0   \n",
       "2348943          0.051020        0.051020           0.102041      1.0   \n",
       "4609643          0.071429        0.071429           0.102041      0.0   \n",
       "...                   ...             ...                ...      ...   \n",
       "4737115          0.028571        0.028571           0.028571      0.0   \n",
       "8302275          0.028571        0.028571           0.028571      0.0   \n",
       "1948278          0.000000        0.051020           0.000000      1.0   \n",
       "1765768          0.028571        0.028571           0.000000      1.0   \n",
       "8168288          0.051020        0.051020           0.000000      1.0   \n",
       "\n",
       "          amt_2_4  amt_3_4   amt_4_4  0  1  2  3  4  5  6  7  8  9  10  11  \\\n",
       "1481322  0.000000     0.00  0.000000  0  0  0  0  0  0  0  0  0  0   0   0   \n",
       "5214926  0.000000     0.00  0.000000  0  0  0  0  0  0  0  0  0  0   1   0   \n",
       "8291594  1.000000     0.00  0.000000  0  0  0  0  0  0  1  0  0  1   0   0   \n",
       "2348943  0.000000     0.00  0.000000  0  0  0  0  0  0  0  0  0  0   0   0   \n",
       "4609643  0.000000     0.50  0.500000  0  0  0  0  0  0  0  0  0  0   0   0   \n",
       "...           ...      ...       ... .. .. .. .. .. .. .. .. .. ..  ..  ..   \n",
       "4737115  0.166667     0.00  0.833333  0  0  0  0  0  0  0  0  0  0   1   0   \n",
       "8302275  0.750000     0.25  0.000000  0  0  0  0  0  0  0  0  0  0   0   1   \n",
       "1948278  0.000000     0.00  0.000000  0  0  0  0  0  0  1  0  0  0   0   0   \n",
       "1765768  0.000000     0.00  0.000000  0  0  0  0  0  0  0  0  0  0   0   1   \n",
       "8168288  0.000000     0.00  0.000000  1  0  0  0  0  0  0  0  0  0   0   0   \n",
       "\n",
       "         12  13  14  15  16  17  18  19  20  21  22  23  24  25  26  27  28  \\\n",
       "1481322   0   0   0   1   0   0   0   0   0   0   0   0   0   0   0   0   0   \n",
       "5214926   0   0   0   1   0   0   0   0   0   0   0   0   0   0   0   0   0   \n",
       "8291594   0   0   0   1   0   0   0   0   0   0   0   0   0   0   0   0   0   \n",
       "2348943   0   0   0   1   0   0   0   0   0   0   0   0   0   0   0   0   0   \n",
       "4609643   0   0   0   1   0   0   0   0   0   0   0   0   0   0   0   0   0   \n",
       "...      ..  ..  ..  ..  ..  ..  ..  ..  ..  ..  ..  ..  ..  ..  ..  ..  ..   \n",
       "4737115   0   0   0   1   0   0   0   0   0   0   0   0   0   0   0   0   0   \n",
       "8302275   0   0   0   1   0   0   0   0   0   0   0   0   0   0   0   0   0   \n",
       "1948278   0   0   0   1   0   0   0   0   0   0   0   0   0   0   0   0   0   \n",
       "1765768   0   0   0   1   0   0   0   0   0   0   0   0   0   0   0   0   0   \n",
       "8168288   0   0   0   1   0   0   0   0   1   0   0   0   0   0   0   0   0   \n",
       "\n",
       "         29  30  31  \n",
       "1481322   1   0   0  \n",
       "5214926   0   0   0  \n",
       "8291594   0   0   0  \n",
       "2348943   1   0   0  \n",
       "4609643   0   1   0  \n",
       "...      ..  ..  ..  \n",
       "4737115   0   0   0  \n",
       "8302275   0   0   0  \n",
       "1948278   0   0   0  \n",
       "1765768   0   0   0  \n",
       "8168288   0   0   0  \n",
       "\n",
       "[7397961 rows x 46 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sa_id</th>\n",
       "      <th>album_id</th>\n",
       "      <th>label</th>\n",
       "      <th>buy_seg</th>\n",
       "      <th>buy_tot</th>\n",
       "      <th>release_date</th>\n",
       "      <th>run_time</th>\n",
       "      <th>movie_meta_price</th>\n",
       "      <th>i30_meta_price</th>\n",
       "      <th>buy_history_price</th>\n",
       "      <th>amt_1_4</th>\n",
       "      <th>amt_2_4</th>\n",
       "      <th>amt_3_4</th>\n",
       "      <th>amt_4_4</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "      <th>20</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "      <th>25</th>\n",
       "      <th>26</th>\n",
       "      <th>27</th>\n",
       "      <th>28</th>\n",
       "      <th>29</th>\n",
       "      <th>30</th>\n",
       "      <th>31</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8295279</th>\n",
       "      <td>170230</td>\n",
       "      <td>2148</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.741581</td>\n",
       "      <td>0.254642</td>\n",
       "      <td>0.051020</td>\n",
       "      <td>0.051020</td>\n",
       "      <td>0.028571</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3331943</th>\n",
       "      <td>89183</td>\n",
       "      <td>1580</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.928741</td>\n",
       "      <td>0.270557</td>\n",
       "      <td>0.028571</td>\n",
       "      <td>0.028571</td>\n",
       "      <td>0.028571</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8685656</th>\n",
       "      <td>184299</td>\n",
       "      <td>5648</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.952833</td>\n",
       "      <td>0.262599</td>\n",
       "      <td>0.028571</td>\n",
       "      <td>0.028571</td>\n",
       "      <td>0.028571</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4595249</th>\n",
       "      <td>620039</td>\n",
       "      <td>4007</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.871146</td>\n",
       "      <td>0.230769</td>\n",
       "      <td>0.028571</td>\n",
       "      <td>0.018367</td>\n",
       "      <td>0.028571</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4896992</th>\n",
       "      <td>524107</td>\n",
       "      <td>2002</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.929324</td>\n",
       "      <td>0.212202</td>\n",
       "      <td>0.028571</td>\n",
       "      <td>0.028571</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4254390</th>\n",
       "      <td>790508</td>\n",
       "      <td>517</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.776483</td>\n",
       "      <td>0.485411</td>\n",
       "      <td>0.028571</td>\n",
       "      <td>0.028571</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4092322</th>\n",
       "      <td>268626</td>\n",
       "      <td>3325</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.003003</td>\n",
       "      <td>0.941430</td>\n",
       "      <td>0.310345</td>\n",
       "      <td>0.028571</td>\n",
       "      <td>0.028571</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7038757</th>\n",
       "      <td>437720</td>\n",
       "      <td>9191</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.988008</td>\n",
       "      <td>0.350133</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9143437</th>\n",
       "      <td>919312</td>\n",
       "      <td>9439</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.952833</td>\n",
       "      <td>0.376658</td>\n",
       "      <td>0.051020</td>\n",
       "      <td>0.051020</td>\n",
       "      <td>0.102041</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4143049</th>\n",
       "      <td>350697</td>\n",
       "      <td>8184</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.987883</td>\n",
       "      <td>0.480106</td>\n",
       "      <td>0.132653</td>\n",
       "      <td>0.132653</td>\n",
       "      <td>0.202041</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1849491 rows × 46 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          sa_id  album_id  label  buy_seg   buy_tot  release_date  run_time  \\\n",
       "8295279  170230      2148      0        2  0.000000      0.741581  0.254642   \n",
       "3331943   89183      1580      1        3  0.000000      0.928741  0.270557   \n",
       "8685656  184299      5648      0        2  0.000000      0.952833  0.262599   \n",
       "4595249  620039      4007      0        2  0.000000      0.871146  0.230769   \n",
       "4896992  524107      2002      0        3  0.000000      0.929324  0.212202   \n",
       "...         ...       ...    ...      ...       ...           ...       ...   \n",
       "4254390  790508       517      1        2  0.000000      0.776483  0.485411   \n",
       "4092322  268626      3325      1        0  0.003003      0.941430  0.310345   \n",
       "7038757  437720      9191      1        2  0.000000      0.988008  0.350133   \n",
       "9143437  919312      9439      0        3  0.000000      0.952833  0.376658   \n",
       "4143049  350697      8184      1        2  0.000000      0.987883  0.480106   \n",
       "\n",
       "         movie_meta_price  i30_meta_price  buy_history_price  amt_1_4  \\\n",
       "8295279          0.051020        0.051020           0.028571      1.0   \n",
       "3331943          0.028571        0.028571           0.028571      1.0   \n",
       "8685656          0.028571        0.028571           0.028571      0.0   \n",
       "4595249          0.028571        0.018367           0.028571      0.0   \n",
       "4896992          0.028571        0.028571           0.000000      1.0   \n",
       "...                   ...             ...                ...      ...   \n",
       "4254390          0.028571        0.028571           0.000000      1.0   \n",
       "4092322          0.028571        0.028571           0.000000      1.0   \n",
       "7038757          0.000000        0.000000           0.000000      1.0   \n",
       "9143437          0.051020        0.051020           0.102041      0.0   \n",
       "4143049          0.132653        0.132653           0.202041      0.0   \n",
       "\n",
       "          amt_2_4   amt_3_4   amt_4_4  0  1  2  3  4  5  6  7  8  9  10  11  \\\n",
       "8295279  0.000000  0.000000  0.000000  0  0  0  0  0  0  0  0  0  0   1   0   \n",
       "3331943  0.000000  0.000000  0.000000  0  1  0  0  0  0  0  0  1  0   0   0   \n",
       "8685656  0.875000  0.000000  0.125000  0  0  0  0  0  0  0  0  0  0   1   0   \n",
       "4595249  0.142857  0.142857  0.714286  0  0  0  0  0  0  0  0  0  0   0   0   \n",
       "4896992  0.000000  0.000000  0.000000  0  0  0  0  0  0  0  0  0  0   0   0   \n",
       "...           ...       ...       ... .. .. .. .. .. .. .. .. .. ..  ..  ..   \n",
       "4254390  0.000000  0.000000  0.000000  0  0  0  0  0  0  0  0  0  0   0   0   \n",
       "4092322  0.000000  0.000000  0.000000  0  0  0  0  0  0  0  0  0  0   0   0   \n",
       "7038757  0.000000  0.000000  0.000000  0  0  0  0  0  1  0  0  0  0   0   1   \n",
       "9143437  0.500000  0.500000  0.000000  0  0  0  0  0  0  0  0  0  0   0   0   \n",
       "4143049  0.000000  0.333333  0.666667  0  0  0  0  0  0  0  0  0  0   0   0   \n",
       "\n",
       "         12  13  14  15  16  17  18  19  20  21  22  23  24  25  26  27  28  \\\n",
       "8295279   0   0   0   1   0   0   0   0   0   0   0   0   0   0   0   0   0   \n",
       "3331943   1   0   0   1   0   0   0   0   0   0   1   0   0   0   0   0   0   \n",
       "8685656   0   0   0   1   0   0   0   0   0   0   0   0   0   0   0   0   0   \n",
       "4595249   0   0   0   1   0   0   0   0   0   0   0   0   0   0   0   0   0   \n",
       "4896992   1   0   0   1   0   0   0   0   0   0   1   0   0   0   0   0   0   \n",
       "...      ..  ..  ..  ..  ..  ..  ..  ..  ..  ..  ..  ..  ..  ..  ..  ..  ..   \n",
       "4254390   0   0   0   1   0   0   0   0   0   0   0   0   0   0   0   0   0   \n",
       "4092322   0   0   0   1   0   0   0   0   0   0   0   0   0   0   0   0   0   \n",
       "7038757   0   0   0   1   0   0   0   0   0   0   0   0   0   0   0   0   0   \n",
       "9143437   0   0   0   1   0   0   0   0   0   0   0   0   0   0   0   0   0   \n",
       "4143049   0   0   0   1   0   0   0   0   0   0   0   0   0   0   0   0   0   \n",
       "\n",
       "         29  30  31  \n",
       "8295279   0   0   0  \n",
       "3331943   0   0   0  \n",
       "8685656   0   0   0  \n",
       "4595249   0   1   0  \n",
       "4896992   0   0   0  \n",
       "...      ..  ..  ..  \n",
       "4254390   1   0   0  \n",
       "4092322   1   0   0  \n",
       "7038757   0   0   0  \n",
       "9143437   1   0   0  \n",
       "4143049   1   0   0  \n",
       "\n",
       "[1849491 rows x 46 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./model/all_w_genre_neg_2e18batch/assets\n"
     ]
    }
   ],
   "source": [
    "model.save(filepath='./model/all_w_genre_neg_2e18batch/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tensorflow2_latest_p37]",
   "language": "python",
   "name": "conda-env-tensorflow2_latest_p37-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
